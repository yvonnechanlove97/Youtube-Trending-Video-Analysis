{"cells":[{"cell_type":"markdown","source":["### Problem statement\nYouTube is the most popular video website in the world. They mantain a list of the top trending videos of every day which are selected by their own algorithms based on many factors of a video aside from just the number of views. As a YouTube user, it would be very interesting to find out insights about the trending and hopefully come out patterns that can help YouTubers to be more successful with their channels. Having considered that there is no suitable target variables in the dataset, thus, in this project, I would only focus on data visualization."],"metadata":{}},{"cell_type":"markdown","source":["### Data\n* The dataset is a csv file conataing a list of the trending YouTube videos from 2017-11 to 2018-06 in the US and Canada including the video title, channel title, category_id, publish time, tags, views, likes and dislikes, description, and comment count.  \n* The 'category_id' varies bewteen regions with the specific category in associated JSON files.\n\n### Method\nIn this project, **Spark** will be used for data preparation and data wrangling, **Python** will be used for data visulization."],"metadata":{}},{"cell_type":"code","source":["#Import data and drop useless columns\nus = spark.read.csv('/FileStore/tables/USvideos.csv', header=\"true\", inferSchema=\"true\").drop('description','comment_disabled','ratings_disabled','video_error_or_removed')\nca = spark.read.csv('/FileStore/tables/CAvideos.csv', header=\"true\", inferSchema=\"true\").drop('description','comment_disabled','ratings_disabled','video_error_or_removed')\nus.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[53]: Row(video_id=&#39;2kyS6SvSYSE&#39;, trending_date=&#39;17.14.11&#39;, title=&#39;WE WANT TO TALK ABOUT OUR MARRIAGE&#39;, channel_title=&#39;CaseyNeistat&#39;, category_id=&#39;22&#39;, publish_time=&#39;2017-11-13T17:13:01.000Z&#39;, tags=&#39;SHANtell martin&#39;, views=&#39;748374&#39;, likes=&#39;57527&#39;, dislikes=&#39;2966&#39;, comment_count=&#39;15954&#39;, thumbnail_link=&#39;https://i.ytimg.com/vi/2kyS6SvSYSE/default.jpg&#39;, comments_disabled=&#39;False&#39;)</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["In our current dataframe, the category column is in numbers instead of the strings. The according strings are in a nested JSON file. Next, the number category will be converted to the real category name."],"metadata":{}},{"cell_type":"code","source":["#Insert category column\nus_cate=spark.read.json(\"/FileStore/tables/US_category_id.json\",multiLine=True)\nca_cate=spark.read.json(\"/FileStore/tables/CA_category_id.json\",multiLine=True)\n\nfrom pyspark.sql.functions import explode\nfrom pyspark.sql.functions import monotonically_increasing_id\n\n#US area category\nus_cate_df=us_cate.select('items.id',\"items.snippet.title\")\nus_id=us_cate_df.select(explode(\"id\").alias(\"id\"))\nus_title=us_cate_df.select(explode(\"title\").alias(\"category\"))\nus_id = us_id.withColumn(\"index\", monotonically_increasing_id())\nus_title = us_title.withColumn(\"index\", monotonically_increasing_id())\ndf1 = us_title.join(us_id, \"index\", \"outer\").drop(\"index\")\nus=us.withColumnRenamed('category_id', 'id')\nus=us.join(df1,'id',how='left').drop('id')\n\n#CA area category\nca_cate_df=ca_cate.select('items.id',\"items.snippet.title\")\nca_id=ca_cate_df.select(explode(\"id\").alias(\"id\"))\nca_title=ca_cate_df.select(explode(\"title\").alias(\"category\"))\nca_id = ca_id.withColumn(\"index\", monotonically_increasing_id())\nca_title = ca_title.withColumn(\"index\", monotonically_increasing_id())\ndf2 = ca_title.join(ca_id, \"index\", \"outer\").drop(\"index\")\nca=ca.withColumnRenamed('category_id', 'id')\nca=ca.join(df2,'id',how='left').drop('id')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["#combine two datasets into one\ndf=us.union(ca)\n#Check missing values\nfrom pyspark.sql.functions import count\ndef my_count(df):\n  df.agg(*[count(c).alias(c) for c in df.columns]).show()\n\nmy_count(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------------+-----+-------------+------------+-----+-----+-----+--------+-------------+--------------+-----------------+--------+\nvideo_id|trending_date|title|channel_title|publish_time| tags|views|likes|dislikes|comment_count|thumbnail_link|comments_disabled|category|\n+--------+-------------+-----+-------------+------------+-----+-----+-----+--------+-------------+--------------+-----------------+--------+\n   93697|        83922|83618|        83433|       82816|82096|82007|81981|   81973|        81970|         81970|            81955|   81756|\n+--------+-------------+-----+-------------+------------+-----+-----+-----+--------+-------------+--------------+-----------------+--------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Combine two datasets into one set and adjust the incorrect data type and Check missing values"],"metadata":{}},{"cell_type":"code","source":["#drop rows contains missing values\ndf=df.na.drop()\nmy_count(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------------+-----+-------------+------------+-----+-----+-----+--------+-------------+--------------+-----------------+--------+\nvideo_id|trending_date|title|channel_title|publish_time| tags|views|likes|dislikes|comment_count|thumbnail_link|comments_disabled|category|\n+--------+-------------+-----+-------------+------------+-----+-----+-----+--------+-------------+--------------+-----------------+--------+\n   81756|        81756|81756|        81756|       81756|81756|81756|81756|   81756|        81756|         81756|            81756|   81756|\n+--------+-------------+-----+-------------+------------+-----+-----+-----+--------+-------------+--------------+-----------------+--------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["When importing the data, all variables were treated as string. There are some numerical variables, therefore we need to convert it into double datatype."],"metadata":{}},{"cell_type":"code","source":["#transfer data type\nfrom pyspark.sql.functions import col , column, to_date, unix_timestamp\nnum_col=['views','likes','dislikes','comment_count']\nfor n in num_col:\n  df = df.withColumn(n, col(n).cast(\"double\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Add two new variables for future use. One is the ratio of likes over views which can indicates the percentage of likes, one is the ratio of dislikes over views indicating the percentage of dislikes."],"metadata":{}},{"cell_type":"code","source":["import pyspark.sql.functions as func\ndf=df.withColumn('likes_ratio',func.round(df.likes/df.views,4))\ndf=df.withColumn('dislikes_ratio',func.round(df.dislikes/df.views,4))\ndf.printSchema"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[40]: &lt;bound method DataFrame.printSchema of DataFrame[video_id: string, trending_date: string, title: string, channel_title: string, publish_time: string, tags: string, views: double, likes: double, dislikes: double, comment_count: double, thumbnail_link: string, comments_disabled: string, category: string, likes_ratio: double, dislikes_ratio: double]&gt;</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["Since the filtered dataset is not quite large, at the later part, it would be transfered into Pandas for the convenience of data visualizaiton."],"metadata":{}},{"cell_type":"code","source":["#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["#transfer into pandas.dataframe\npd_df=df.toPandas() \npd_df.info()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 81756 entries, 0 to 81755\nData columns (total 15 columns):\nvideo_id             81756 non-null object\ntrending_date        81756 non-null object\ntitle                81756 non-null object\nchannel_title        81756 non-null object\npublish_time         81756 non-null object\ntags                 81756 non-null object\nviews                81756 non-null float64\nlikes                81756 non-null float64\ndislikes             81756 non-null float64\ncomment_count        81756 non-null float64\nthumbnail_link       81756 non-null object\ncomments_disabled    81756 non-null object\ncategory             81756 non-null object\nlikes_ratio          81756 non-null float64\ndislikes_ratio       81756 non-null float64\ndtypes: float64(6), object(9)\nmemory usage: 9.4+ MB\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["* Considering 'trending_date' and 'publish_time' are datetime variables, it is better to transfer them into datetime type instead of object type. \n* Remove some duplicates records by only keeping the lastest record"],"metadata":{}},{"cell_type":"code","source":["#transfer the time datetype\npd_df['trending_date'] = pd.to_datetime(pd_df['trending_date'], format='%y.%d.%m').dt.date\npublish_time = pd.to_datetime(pd_df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\npd_df['publish_time']=publish_time\n#remove duplicates and only keep the lastest record\npd_df=pd_df.sort_values('publish_time',ascending=True).drop_duplicates(subset=['video_id'],keep='last')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["#seperate the publish time into date, time and hour for future use\npd_df['publish_date'] = publish_time.dt.date\npd_df['publish_time'] = publish_time.dt.time\npd_df['publish_hour'] = publish_time.dt.hour"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["### Data Visualazation\n#### 1. Correlations between views,likes,dislikes,comment_count,likes_ratio,dislikes_ratio."],"metadata":{}},{"cell_type":"code","source":["corr=pd_df.loc[:,[\"views\",\"likes\",\"dislikes\",\"comment_count\",'likes_ratio','dislikes_ratio']].corr()\nax=sns.heatmap(corr,  vmin=-1, vmax=1, center=0,cmap=sns.diverging_palette(20, 220, n=100),square=True)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n)\nplt.title('Heatmap of numeric variables correlations ')\ndisplay(ax)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["From the correlation plot, we can see all numerical variables are either positive correlated or uncorrelated. \n\n- 'Dislikes' and 'likes' do not have a significant relation. However 'likes' and 'views' have a strong relation indicating that videos with more views tends to have more likes. But videos with more views does not tend to have more dislikes as well.\n- 'likes_ratio' and 'dislikes_ratio' seem uncorrelated with other variables indicating these two variables are quite useful."],"metadata":{}},{"cell_type":"markdown","source":["#### 2. Which category is always trending?"],"metadata":{}},{"cell_type":"code","source":["#category plot\nplt.close('all')\nfig, ax = plt.subplots()\ncat_df_us = pd_df['category'].value_counts().reset_index()\nplt.figure(figsize=(15,10))\nsns.set_style(\"whitegrid\")\nax=sns.barplot(x='category',y='index',data=cat_df_us)\nplt.xlabel(\"Number of Videos\")\nplt.ylabel(\"Categories\")\nplt.title(\"Catogories of trend videos\")\ndisplay(ax)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["From the barplot,\n* **Top**: Among all the trending videos, the number of Entertainment videos is significantly much higher than the other categories. It is over two times as the second highest category which is News & Politics.  \n + _*This phenomenon aligns with common sense, becuase people watch YouTube for entertainment when they are free in general. News & Politics videos often get trending because there are some breaking news that everyone cares or affect everyone in the area.*_\n\n* **Bottom**: There are few trending videos that belong to Nonprofits & Activism and Movies category. In the plot, one cannot even see it.  \n + _*People do not really watch movies on YouTube and movies are always charged. Besides, movies are too long, no one would click on a three-hour movie even though it is trending. In additions, Nonprofits & Activism is a relatively small genre and thus few trending videos in this category.*_"],"metadata":{}},{"cell_type":"markdown","source":["#### 3. When is the best time in a day to publish video?"],"metadata":{}},{"cell_type":"code","source":["plt.close('all')\nfig, ax = plt.subplots()\nplt.figure(figsize=(15,10))\nax=sns.countplot(x='publish_hour',data=pd_df,palette='Blues_r', order=pd_df['publish_hour'].value_counts().index)\nplt.xticks(rotation=90)\nplt.xlabel('Publish Hour')\nplt.ylabel('Number of Videos')\nplt.title('Publish Hour of trend videos')\ndisplay(ax)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["* In general, most of the trending videos are published in the afternoon or at night\n* 15-17 pm seems to be the best time to release a video"],"metadata":{}},{"cell_type":"markdown","source":["#### 4. Top 10 most liked videos\n_Found the top 10 videos that have the highest like-ratio_"],"metadata":{}},{"cell_type":"code","source":["from IPython.display import HTML\ncol=['thumbnail_link','title','views','likes_ratio','dislikes_ratio','category']\nmost_frequent=pd_df[col].sort_values(\"likes_ratio\", ascending=False).head(10)\n\n# Construction of HTML table with miniature photos assigned to the most popular movies\ntable_content = ''\nmax_title_length = 50\n\nfor date, row in most_frequent.T.iteritems():\n    HTML_row = '<tr>'\n    HTML_row += '<td><img src=\"' + str(row[0]) + '\"style=\"width:100px;height:100px;\"></td>'\n    HTML_row += '<td>' + str(row[1]) + '</td>'\n    HTML_row += '<td>' + str(row[2])  + '</td>'\n    HTML_row += '<td>' + str(row[3]) + '</td>'\n    HTML_row += '<td>' + str(row[4]) + '</td>'\n    HTML_row += '<td>' + str(row[5]) + '</td>'\n    \n    table_content += HTML_row + '</tr>'\n\ndisplayHTML(\n  '<table><tr><th>Thumbnail</th><th>Title</th><th style=\"width:250px;\">Views</th><th>Likes_ratio</th><th>Dislikes_ratio</th><th>Category</th></tr>{}</table>'.format(table_content))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<table><tr><th>Thumbnail</th><th>Title</th><th style=\"width:250px;\">Views</th><th>Likes_ratio</th><th>Dislikes_ratio</th><th>Category</th></tr><tr><td><img src=\"https://i.ytimg.com/vi/u2Ba65YELoo/default.jpg\"style=\"width:100px;height:100px;\"></td><td>The Reaction of The Streets (I Wait-Day6 Edition)</td><td>88889.0</td><td>0.288</td><td>0.0001</td><td>People & Blogs</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/2xM0Peo7JNI/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Un Film Pour Raphael</td><td>5232.0</td><td>0.2632</td><td>0.001</td><td>Film & Animation</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/STEUAcTmXTg/default.jpg\"style=\"width:100px;height:100px;\"></td><td>[MIXTAPE] I.M - Fly With Me (MV)</td><td>429082.0</td><td>0.2492</td><td>0.0005</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/UaAHl_m_ybk/default.jpg\"style=\"width:100px;height:100px;\"></td><td>5 Seconds Of Summer - Want You Back (Audio)</td><td>439056.0</td><td>0.2426</td><td>0.0015</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/DqihQBYEPas/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Il fallait que je vous dise...</td><td>4739.0</td><td>0.2399</td><td>0.0006</td><td>Comedy</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/cB12p-Wm5HY/default.jpg\"style=\"width:100px;height:100px;\"></td><td>VOUS ÊTES DÉJÀ ALLÉ EN MUSULMANIE ? (Ramadan voxpop)</td><td>2242.0</td><td>0.2386</td><td>0.0027</td><td>Comedy</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/6mC4H2mn6Uo/default.jpg\"style=\"width:100px;height:100px;\"></td><td>YOUTUBE DISS TRACK</td><td>82487.0</td><td>0.2365</td><td>0.0025</td><td>Gaming</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/OB6_vByiBjo/default.jpg\"style=\"width:100px;height:100px;\"></td><td>SLOGOMAN REACTS TO GO GET GONE - KWEBBELKOP & SLOGOMAN DISS TRACK</td><td>348156.0</td><td>0.2342</td><td>0.003</td><td>Gaming</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/PMEkmiQP5bg/default.jpg\"style=\"width:100px;height:100px;\"></td><td>G.C.F in Osaka</td><td>2942269.0</td><td>0.2341</td><td>0.0002</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/zb_lcTj81AQ/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Day6 Tomfoolery in NY and Japan</td><td>98947.0</td><td>0.2299</td><td>0.0002</td><td>People & Blogs</td></tr></table>"]}}],"execution_count":29},{"cell_type":"markdown","source":["* Trending videos do not always have the most views. Many from the top 10 which have high like-ratio over views got into trending have only a few thousands views. \n* Likes_ratio seems to be an important part of YouTube trending videos Algorithm.\n* Most liked videos do not domain in one or two categories, their categories vary."],"metadata":{}},{"cell_type":"markdown","source":["#### 5. Top 10 most viewd videos\n_Found the top 10 videos that have the highest views_"],"metadata":{}},{"cell_type":"code","source":["col=['thumbnail_link','title','views','likes_ratio','dislikes_ratio','category']\npd_df[pd_df.category!='Music']\nmost_frequent=pd_df[col].sort_values(\"views\", ascending=False).head(10)\n\n# Construction of HTML table with miniature photos assigned to the most popular movies\ntable_content = ''\nmax_title_length = 50\n\nfor date, row in most_frequent.T.iteritems():\n    HTML_row = '<tr>'\n    HTML_row += '<td><img src=\"' + str(row[0]) + '\"style=\"width:100px;height:100px;\"></td>'\n    HTML_row += '<td>' + str(row[1]) + '</td>'\n    HTML_row += '<td>' + str(row[2])  + '</td>'\n    HTML_row += '<td>' + str(row[3]) + '</td>'\n    HTML_row += '<td>' + str(row[4]) + '</td>'\n    HTML_row += '<td>' + str(row[5]) + '</td>'\n    \n    table_content += HTML_row + '</tr>'\n\ndisplayHTML(\n  '<table><tr><th>Thumbnail</th><th>Title</th><th style=\"width:250px;\">Views</th><th>Likes_ratio</th><th>Dislikes_ratio</th><th>Category</th></tr>{}</table>'.format(table_content))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<table><tr><th>Thumbnail</th><th>Title</th><th style=\"width:250px;\">Views</th><th>Likes_ratio</th><th>Dislikes_ratio</th><th>Category</th></tr><tr><td><img src=\"https://i.ytimg.com/vi/VYOjWnS4cMY/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Childish Gambino - This Is America (Official Video)</td><td>210338856.0</td><td>0.023</td><td>0.0016</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/ffxKSjUwKdU/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Ariana Grande - No Tears Left To Cry</td><td>101386547.0</td><td>0.0275</td><td>0.0011</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/6ZfuNTqbHE8/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Marvel Studios' Avengers: Infinity War Official Trailer</td><td>84281319.0</td><td>0.0303</td><td>0.0006</td><td>Entertainment</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/TyHvyGVs42U/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Luis Fonsi, Demi Lovato - Échame La Culpa</td><td>68997838.0</td><td>0.0297</td><td>0.0014</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/DkeiKbqa02g/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Calvin Harris, Dua Lipa - One Kiss (Official Video)</td><td>62800938.0</td><td>0.0124</td><td>0.0005</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/7C2z4GqqS5E/default.jpg\"style=\"width:100px;height:100px;\"></td><td>BTS (방탄소년단) 'FAKE LOVE' Official MV</td><td>62796390.0</td><td>0.0712</td><td>0.0019</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/_I_D_8Z4sJE/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Nicky Jam x J. Balvin - X (EQUIS) | Video Oficial | Prod. Afro Bros & Jeon</td><td>61163906.0</td><td>0.0103</td><td>0.0004</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/U9BwWKXjVaI/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Drake - Nice For What</td><td>57582925.0</td><td>0.0169</td><td>0.0006</td><td>Music</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/BhIEIO0vaBE/default.jpg\"style=\"width:100px;height:100px;\"></td><td>To Our Daughter</td><td>56111957.0</td><td>0.0</td><td>0.0</td><td>People & Blogs</td></tr><tr><td><img src=\"https://i.ytimg.com/vi/iWZmdoY1aTE/default.jpg\"style=\"width:100px;height:100px;\"></td><td>Ed Sheeran - Happier (Official Video)</td><td>51747671.0</td><td>0.0263</td><td>0.0006</td><td>Music</td></tr></table>"]}}],"execution_count":32},{"cell_type":"markdown","source":["* Most of the most viewed trending videos are music vedios\n* When the videos get millions of views, the like ratio is not referable anymore\n* Videos from popular singers or popular movie trailer can attract most of the users to click on and tend to get trending"],"metadata":{}},{"cell_type":"markdown","source":["#### 6. What insight does TAGS show"],"metadata":{}},{"cell_type":"code","source":["#wordcloud\nplt.close('all')\nfrom wordcloud import WordCloud \nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n\n#tags_word = pd_df[pd_df['category']=='News & Politics']['tags'].str.lower().str.cat(sep=' ')\ntags_word = pd_df['tags'].str.lower().str.cat(sep=' ')\ntags_word = re.sub('[^A-Za-z]+', ' ', tags_word)\nword_tokens = word_tokenize(tags_word)\nen_stopwords= set(stopwords.words('english'))\nfiltered_sentence = [w for w in word_tokens if not w in en_stopwords]\nwithout_single_chr = [word for word in filtered_sentence if len(word) > 2]\ncleaned_data_title = [word for word in without_single_chr if not word.isdigit()]\n\nfrom collections import Counter\ncounts=Counter(cleaned_data_title)\n\nwordcloud = WordCloud(width=900,height=500, max_words=3000,relative_scaling=1).generate_from_frequencies(counts)\n\nplt.figure(figsize=(14, 10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\ndisplay()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["The size of the word in the wordcloud is based on the frequency of a word in the tags. The higher frequency, the bigger the word size is.  \n<br>\n\n * 'News' and 'Trump' apprently happen very frequently in the news&politics category videos and news&politics do have the second highest number among all the trending videos.\n * Same for the music category with the 'songs' and 'music'\n * Positive words such as 'funny', 'comedy', 'family', 'best', 'challenge', 'highlights' are quite frequent among trending videos."],"metadata":{}},{"cell_type":"markdown","source":["### Recomendations to YouTubers  \n<br>\n- **Do ask your viewers to give likes to the video** becuase it can still push your video to be trending regardless of how many views your video have\n- **Publish your video during 15-17 pm of your day** because most of the trending videos are released during that time\n- **Tag your video with positive words** because the most frequent words are either neutural function words or positive words"],"metadata":{}}],"metadata":{"name":"YouTube Trending Videos EDA","notebookId":1232921705074720},"nbformat":4,"nbformat_minor":0}
